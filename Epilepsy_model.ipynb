{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import Ipython that is used for display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open-source Python package for exploring, visualizing, and analyzing EEGs\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os, os.path\n",
    "from os import listdir\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"../chb-mit/\"\n",
    "dataset_path = './chb-mit/'\n",
    "# spectrograms_path = \"../spectrograms/\"\n",
    "spectrograms_path = './spectrograms/'\n",
    "samples_path = \"./samples/\"\n",
    "\n",
    "\n",
    "if not os.path.exists(samples_path):\n",
    "    os.makedirs(samples_path)\n",
    "    \n",
    "path_train_0 = samples_path + \"train/0/\"\n",
    "path_train_1 = samples_path + \"train/1/\"\n",
    "path_val_0 = samples_path + \"validation/0/\"\n",
    "path_val_1 = samples_path + \"validation/1/\"\n",
    "path_test_0 = samples_path + \"test/0/\"\n",
    "path_test_1 = samples_path + \"test/1/\"\n",
    "\n",
    "#en segundos\n",
    "window_size = 60\n",
    "overlap = 10\n",
    "preictal = 20 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Canales seleccionados para ser analizados\n",
    "\"\"\"\n",
    "\n",
    "#Temporal# channels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8-0', 'P8-O2', 'FZ-CZ', 'CZ-PZ']\n",
    "channels = ['FP1-F7', 'F7-T7', 'T7-P7']\n",
    "\n",
    "n_channels = len(channels)\n",
    "\n",
    "print(n_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset_train(Dataset):\n",
    "    def __init__(self):\n",
    "        self.path0 = path_train_0\n",
    "        self.path1 = path_train_1\n",
    "        self.n0 = len([name for name in os.listdir(path_train_0) if os.path.isfile(os.path.join(path_train_0, name))]) \n",
    "        self.n1 = len([name for name in os.listdir(path_train_1) if os.path.isfile(os.path.join(path_train_1, name))])\n",
    "    def __getitem__(self, index):\n",
    "        if index < self.n0:\n",
    "            file = np.load(self.path0+\"img\"+str(index)+\".npy\")\n",
    "            y = 0\n",
    "        else:\n",
    "            file = np.load(self.path1+\"img\"+str(index-self.n0)+\".npy\")\n",
    "            y = 1\n",
    "\n",
    "        x = file.astype(np.float32)\n",
    "        \n",
    "        x = torch.from_numpy(x)\n",
    "        \n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return self.n0 + self.n1\n",
    "    \n",
    "\"\"\"class EEGDataset_validation(Dataset):\n",
    "    def __init__(self):\n",
    "        self.path0 = path_val_0\n",
    "        self.path1 = path_val_1\n",
    "    def __getitem__(self, index):\n",
    "        if index <= 500:\n",
    "            file = np.load(self.path0+\"img\"+str(index+5000)+\".npy\")\n",
    "            y = 0\n",
    "        else:\n",
    "            file = np.load(self.path1+\"img\"+str(index+5000-500)+\".npy\")\n",
    "            y = 1\n",
    "\n",
    "        x = file.astype(np.float32)\n",
    "        \n",
    "        x = torch.from_numpy(x)\n",
    "        \n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return 1000\"\"\"\n",
    "    \n",
    "class EEGDataset_test(Dataset):\n",
    "    def __init__(self):\n",
    "        self.path0 = path_test_0\n",
    "        self.path1 = path_test_1\n",
    "        self.n0 = len([name for name in os.listdir(path_test_0) if os.path.isfile(os.path.join(path_test_0, name))]) \n",
    "        self.n1 = len([name for name in os.listdir(path_test_1) if os.path.isfile(os.path.join(path_test_1, name))])\n",
    "    def __getitem__(self, index):\n",
    "        if index < self.n0:\n",
    "            file = np.load(self.path0+\"img\"+str(index)+\".npy\")\n",
    "            y = 0\n",
    "        else:\n",
    "            file = np.load(self.path1+\"img\"+str(index-self.n0)+\".npy\")\n",
    "            y = 1\n",
    "\n",
    "        x = file.astype(np.float32)\n",
    "        \n",
    "        x = torch.from_numpy(x)\n",
    "        \n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return self.n0 + self.n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n",
      "342\n",
      "1512\n",
      "1512\n"
     ]
    }
   ],
   "source": [
    "print(len([name for name in os.listdir(path_test_0) if os.path.isfile(os.path.join(path_test_0, name))]) )\n",
    "print(len([name for name in os.listdir(path_test_1) if os.path.isfile(os.path.join(path_test_1, name))]) )\n",
    "print(len([name for name in os.listdir(path_train_0) if os.path.isfile(os.path.join(path_train_0, name))]) )\n",
    "print(len([name for name in os.listdir(path_train_1) if os.path.isfile(os.path.join(path_train_1, name))]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datatiter = iter(loader_train)\\ndata = datatiter.next()\\nfeatures, labels = data\\nprint(features, labels)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = EEGDataset_train()\n",
    "#dataset_validation = EEGDataset_validation()\n",
    "dataset_test = EEGDataset_test()\n",
    "loader_train = DataLoader(dataset=dataset_train, batch_size=16, shuffle=True, )\n",
    "#loader_validation = DataLoader(dataset=dataset_validation, batch_size=64, shuffle=True, )\n",
    "loader_test = DataLoader(dataset=dataset_test, batch_size=16, shuffle=True, )\n",
    "\n",
    "\n",
    "\"\"\"datatiter = iter(loader_train)\n",
    "data = datatiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Selecciona cuda si estÃ¡ disponible\n",
    "USE_GPU = True\n",
    "dtype = torch.float32\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function is provided to check the accuracy of the \n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  \n",
    "    with torch.no_grad(): # We need to manually specify that no gradient needs to be computed\n",
    "        for x, y in loader: # Get data from data loader\n",
    "            x = x.to(device=device, dtype=dtype)  # run on selected device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x) #computer forward model    \n",
    "                    \n",
    "            _, preds = scores.max(1)# max returns both max values and indices, we discard the values\n",
    "                                    # preds will contain the indices of the classes with highest score (recall the index represents the class)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=64, kernel_size=3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv4.weight)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv5.weight)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=64*93*120, out_features=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "        \n",
    "        self.m = nn.BatchNorm2d(64, affine=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        \"\"\"x = F.relu(self.m(self.conv4(x)))\n",
    "        x = F.relu(self.m(self.conv5(x)))\"\"\"\n",
    "        x = x.view(-1, 64*93*120)\n",
    "        scores = self.fc(x)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, num_epochs=5):\n",
    "    \n",
    "    model = model.to(device=device)\n",
    "    for e in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(loader_train, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device=device), labels.to(device=device)\n",
    "            \n",
    "            \n",
    "            pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()         \n",
    "    \n",
    "        acc = check_accuracy(loader_test, model)\n",
    "        print(loss.item())\n",
    "        print('Epoch: %i Accuracy: %f %%' % (e, acc))\n",
    "                    \n",
    "learning_rate = 3.5e-7\n",
    "num_epochs = 5\n",
    "\n",
    "model = CNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429606676101685\n",
      "Epoch: 0 Accuracy: 71.929825 %\n",
      "0.6433526873588562\n",
      "Epoch: 1 Accuracy: 71.491228 %\n",
      "0.5661157369613647\n",
      "Epoch: 2 Accuracy: 72.076023 %\n",
      "0.7867354154586792\n",
      "Epoch: 3 Accuracy: 72.953216 %\n",
      "0.6707269549369812\n",
      "Epoch: 4 Accuracy: 72.222222 %\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.107143 %\n"
     ]
    }
   ],
   "source": [
    "acc = check_accuracy(loader_train, model)\n",
    "print('Accuracy: %f %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
